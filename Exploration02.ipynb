{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "advanced-purple",
   "metadata": {},
   "source": [
    "#  Load_digits 손글씨 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-huntington",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "steady-phenomenon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92        32\n",
      "           1       0.93      0.72      0.81        36\n",
      "           2       0.96      0.73      0.83        30\n",
      "           3       0.74      0.83      0.78        41\n",
      "           4       0.80      0.88      0.84        32\n",
      "           5       0.90      0.93      0.91        46\n",
      "           6       0.93      0.88      0.90        32\n",
      "           7       0.90      0.93      0.91        40\n",
      "           8       0.77      0.81      0.79        42\n",
      "           9       0.69      0.76      0.72        29\n",
      "\n",
      "    accuracy                           0.84       360\n",
      "   macro avg       0.85      0.84      0.84       360\n",
      "weighted avg       0.85      0.84      0.84       360\n",
      " Accuracy:  0.8444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        32\n",
      "           1       0.97      1.00      0.99        36\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       0.98      0.98      0.98        41\n",
      "           4       0.94      0.97      0.95        32\n",
      "           5       1.00      0.98      0.99        46\n",
      "           6       1.00      0.97      0.98        32\n",
      "           7       0.98      1.00      0.99        40\n",
      "           8       0.93      0.98      0.95        42\n",
      "           9       1.00      0.93      0.96        29\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.98      0.97      0.97       360\n",
      "weighted avg       0.98      0.97      0.98       360\n",
      " Accuracy:  0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        32\n",
      "           1       0.95      1.00      0.97        36\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       1.00      1.00      1.00        41\n",
      "           4       0.97      1.00      0.98        32\n",
      "           5       0.98      1.00      0.99        46\n",
      "           6       1.00      1.00      1.00        32\n",
      "           7       1.00      1.00      1.00        40\n",
      "           8       0.98      0.95      0.96        42\n",
      "           9       1.00      0.93      0.96        29\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      " Accuracy:  0.9861111111111112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.95      0.97      0.96        36\n",
      "           2       0.97      1.00      0.98        30\n",
      "           3       0.97      0.88      0.92        41\n",
      "           4       0.97      1.00      0.98        32\n",
      "           5       0.95      0.91      0.93        46\n",
      "           6       0.97      1.00      0.98        32\n",
      "           7       1.00      1.00      1.00        40\n",
      "           8       0.91      0.93      0.92        42\n",
      "           9       0.93      0.97      0.95        29\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.97      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      " Accuracy:  0.9611111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.95      0.97      0.96        36\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       0.98      1.00      0.99        41\n",
      "           4       0.94      0.97      0.95        32\n",
      "           5       0.98      0.98      0.98        46\n",
      "           6       1.00      1.00      1.00        32\n",
      "           7       0.97      0.97      0.97        40\n",
      "           8       1.00      0.95      0.98        42\n",
      "           9       0.96      0.93      0.95        29\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      " Accuracy:  0.9777777777777777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "#1. 데이터 준비하기\n",
    "digits = load_digits()\n",
    "#print(dir(digits))   #어떤변수랑 메서드 가지고있는지 확인\n",
    "digits_data = digits.data\n",
    "digits_label = digits.target\n",
    "#digits.target_names  #Target Names 출력해 보기\n",
    "#print(digits.DESCR)  #데이터 Describe 해 보기\n",
    "\n",
    "\n",
    "#2. train, test데이터 분리하기\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_label, test_size=0.2, random_state=21)\n",
    "\n",
    "\n",
    "#3. 여러가지 모델 학습 및 예측해보기\n",
    "# DecisionTree로 분류해보기 \n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred),'Accuracy: ', accuracy)\n",
    "\n",
    "\n",
    "#Random Forest 사용 \n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred),'Accuracy: ', accuracy)\n",
    "\n",
    "\n",
    "#svm모델 사용\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred),'Accuracy: ', accuracy)\n",
    "\n",
    "\n",
    "#SGD Classifier 사용 \n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred),'Accuracy: ', accuracy)\n",
    "\n",
    "\n",
    "#Logistic Regression 사용 - 0.978\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred),'Accuracy: ', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-modem",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-dominant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-condition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "durable-envelope",
   "metadata": {},
   "source": [
    "# Load_wine - 와인 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interior-meeting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      " Accuracy:  0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      " Accuracy:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.58      0.88      0.70        17\n",
      "           2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      " Accuracy:  0.6111111111111112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      1.00      0.52         7\n",
      "           1       0.75      0.71      0.73        17\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.53        36\n",
      "   macro avg       0.37      0.57      0.42        36\n",
      "weighted avg       0.42      0.53      0.44        36\n",
      " Accuracy:  0.5277777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92         7\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.95      0.96        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      " Accuracy:  0.9722222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#1. 데이터 준비하기\n",
    "wine = load_wine()\n",
    "wine_data = wine.data\n",
    "wine_label = wine.target\n",
    "\n",
    "#2. train, test 데이터 분리하기\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_data, wine_label, test_size=0.2, random_state=7)\n",
    "\n",
    "\n",
    "#3. 모델 학습 및 예측\n",
    "#3. 여러가지 모델 학습 및 예측해보기\n",
    "#DecisionTree로 분류해보기\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred),'Accuracy: ', accuracy)\n",
    "\n",
    "\n",
    "#Random Forest 사용 \n",
    "#random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred),'Accuracy: ', accuracy)\n",
    "\n",
    "\n",
    "# svm모델 사용\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred),'Accuracy: ', accuracy)\n",
    "\n",
    "\n",
    "#SGD Classifier 사용 \n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred),'Accuracy: ', accuracy)\n",
    "\n",
    "\n",
    "\n",
    "#Logistic Regression 사용 \n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred),'Accuracy: ', accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-answer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-moisture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-finger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "frequent-grill",
   "metadata": {},
   "source": [
    "# load_breast_cancer - 유방암 여부를 진단하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-thousand",
   "metadata": {},
   "source": [
    "암 환자인데 암 환자가 아니라고 하는 경우를 최대한 줄이는게 좋기때문에 recall이 중요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "later-quick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        40\n",
      "           1       0.91      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.89      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      " Accuracy:  0.9122807017543859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      " Accuracy:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        40\n",
      "           1       0.87      1.00      0.93        74\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.94      0.86      0.89       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      " Accuracy:  0.9035087719298246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        40\n",
      "           1       0.91      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.89      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      " Accuracy:  0.9122807017543859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        40\n",
      "           1       0.91      1.00      0.95        74\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.96      0.91      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      " Accuracy:  0.9385964912280702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#1. 데이터 준비하기\n",
    "breast_cancer = load_breast_cancer()\n",
    "breast_cancer_data = breast_cancer.data\n",
    "breast_cancer_label = breast_cancer.target\n",
    "\n",
    "\n",
    "#2. train, test 데이터 분리하기\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_data, breast_cancer_label, test_size=0.2, random_state=7)\n",
    "\n",
    "\n",
    "#3. 모델 학습 및 예측\n",
    "#3. 여러가지 모델 학습 및 예측해보기\n",
    "#DecisionTree로 분류해보기 \n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred),'Accuracy: ', accuracy)\n",
    "\n",
    "\n",
    "#Random Forest 사용 \n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred),'Accuracy: ', accuracy)\n",
    "\n",
    "\n",
    "\n",
    "#svm모델 사용\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred),'Accuracy: ', accuracy)\n",
    "\n",
    "\n",
    "#SGD Classifier 사용 \n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred),'Accuracy: ', accuracy)\n",
    "\n",
    "\n",
    "#Logistic Regression 사용 \n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred),'Accuracy: ', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-staff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
